# Running a Spark Job on AWS Clustered Environment

Running the Spark Job in the AWS Cloud (write more, introducing what is AWS environment)

I am going to run a python script using the spark engine for python on a dataset with 1 million records.
This will obviosly run on the clustered environment which will be setup at Amazon AWS.

It is obvious, that if this this script is run on a personal computer without any distribution applied to it, the Job will certainly fail. 

So, for this specific piece of code, a clustured environment is necessary. As a matter of fact, in assignments pertaining to Data Science, we tend to encounter Datasets which are often huge, and an example of running huge jobs using a MapReduce clustured environment is quite relevent.

The detailed Steps for setting up AWS as well as preparing the script and Dataset will follow.


